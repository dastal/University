{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 606,
     "status": "ok",
     "timestamp": 1606833557141,
     "user": {
      "displayName": "David Stalder",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgsijLpQ4SIyqjTTwo8axfuAd0nTgHsTIdHbhLpSQ=s64",
      "userId": "06489165530893587391"
     },
     "user_tz": -60
    },
    "id": "UgM7VEXCdbTX",
    "outputId": "2fe7598b-b13d-4870-ab73-09ce0f311894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1606833559024,
     "user": {
      "displayName": "David Stalder",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgsijLpQ4SIyqjTTwo8axfuAd0nTgHsTIdHbhLpSQ=s64",
      "userId": "06489165530893587391"
     },
     "user_tz": -60
    },
    "id": "1BTTm7E7hz51"
   },
   "outputs": [],
   "source": [
    "url_train_dev = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vSZRYmir99b4BqU9UwkJvVIJRBCVgbMye_zDzHwvtjFhvQYJXk9Q3q-spYGse0B5kgVWbEDuxiineIn/pub?gid=1591461788&single=true&output=csv'\n",
    "\n",
    "#url_test = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vT-KNR9nuYatLkSbzSRgpz6Ku1n4TN4w6kKmFLkA6QJHTfQzmX0puBsLF7PAAQJQAxUpgruDd_RRgK7/pub?gid=417546901&single=true&output=tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEtmPp7epxEZ"
   },
   "source": [
    "# Load and inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1606833676845,
     "user": {
      "displayName": "David Stalder",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgsijLpQ4SIyqjTTwo8axfuAd0nTgHsTIdHbhLpSQ=s64",
      "userId": "06489165530893587391"
     },
     "user_tz": -60
    },
    "id": "5D8w9zd1c2IJ"
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import requests\n",
    "\n",
    "def load_dataset(url):\n",
    "    r = requests.get(url)\n",
    "    data = r.content.decode('utf8')\n",
    "    df = pd.read_csv(StringIO(data), sep='\\t')\n",
    "    df.columns = ['bug-id', 'bug', 'label']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 1508,
     "status": "ok",
     "timestamp": 1606833680331,
     "user": {
      "displayName": "David Stalder",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgsijLpQ4SIyqjTTwo8axfuAd0nTgHsTIdHbhLpSQ=s64",
      "userId": "06489165530893587391"
     },
     "user_tz": -60
    },
    "id": "foL-QtlJItoR",
    "outputId": "e0e2fb3f-d57e-48df-f7b5-22968ec76a08"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6784,Missing/incomplete nsIFontEnumerator::HaveFontFor method,blocker\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8166,need to clean up bidi reorder code,blocker\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9574,errno symbols are not always unique on AI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163123,Crash in [@ mozilla::dom::ClientSource:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32333,nsExtensionManager.js should get the XPC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47872,NSS build fails on Windows since 2009021...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>19465,OS/2 - cannot load any page,blocker\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>133411,NSS 3.28 regression in signature scheme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>9661,Multiple XBL interface implementations no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>104432,b2g crashes during closing IPC channel,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>33674,Key navigation (and all shortcuts) broke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   6784,Missing/incomplete nsIFontEnumerator::HaveFontFor method,blocker\"\n",
       "0    8166,need to clean up bidi reorder code,blocker\"                    \n",
       "1   9574,errno symbols are not always unique on AI...                    \n",
       "2   163123,Crash in [@ mozilla::dom::ClientSource:...                    \n",
       "3   32333,nsExtensionManager.js should get the XPC...                    \n",
       "4   47872,NSS build fails on Windows since 2009021...                    \n",
       "..                                                ...                    \n",
       "95         19465,OS/2 - cannot load any page,blocker\"                    \n",
       "96  133411,NSS 3.28 regression in signature scheme...                    \n",
       "97  9661,Multiple XBL interface implementations no...                    \n",
       "98  104432,b2g crashes during closing IPC channel,...                    \n",
       "99  33674,Key navigation (and all shortcuts) broke...                    \n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(url_train_dev)\n",
    "\n",
    "link = \"C:/Users/David/Documents/GitHub/Data_Science_for_Software_Engineering/Project/bug_list.csv\"\n",
    "\n",
    "data = r.content.decode('utf8')\n",
    "\n",
    "df = pd.read_csv(StringIO(data))\n",
    "\n",
    "df.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "executionInfo": {
     "elapsed": 2303,
     "status": "error",
     "timestamp": 1606833691676,
     "user": {
      "displayName": "David Stalder",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgsijLpQ4SIyqjTTwo8axfuAd0nTgHsTIdHbhLpSQ=s64",
      "userId": "06489165530893587391"
     },
     "user_tz": -60
    },
    "id": "DNg0hoBsc5wL",
    "outputId": "106ca6c7-362e-4c65-883d-bd1999a37b6b"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c12f60e004fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_train_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-c14f640ae8f3>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'bug-id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bug'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5150\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5151\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5152\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5153\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5154\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             raise ValueError(\n\u001b[0;32m--> 227\u001b[0;31m                 \u001b[0;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m                 \u001b[0;34mf\"values have {new_len} elements\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 3 elements"
     ]
    }
   ],
   "source": [
    "df_train_dev = load_dataset(url_train_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "executionInfo": {
     "elapsed": 578,
     "status": "error",
     "timestamp": 1606833605830,
     "user": {
      "displayName": "David Stalder",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgsijLpQ4SIyqjTTwo8axfuAd0nTgHsTIdHbhLpSQ=s64",
      "userId": "06489165530893587391"
     },
     "user_tz": -60
    },
    "id": "KWTvXPPgiDzU",
    "outputId": "910a0936-3761-4e6e-a73c-43c35826f700"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infos train-dev-set:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a1544df715f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Infos train-dev-set:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train_dev' is not defined"
     ]
    }
   ],
   "source": [
    "print('Infos train-dev-set:')\n",
    "print(df_train_dev.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "h8lCjkb_kSOp",
    "outputId": "99a21913-9f09-445c-b456-2430d6628c19"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>يا من أناديها ويخنقني البكاء  ويكاد صمت الدمع ...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>فيه فرق بين اهل غزة اللى مطحونين من ناحيتين وب...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ﻋﻦ ﺍﻟﻠﺤﻈﺔ اﻟﺤﻠﻮﺓﺓ ﺍﻟﻠﻲ ﺑﺘﻐﻤﺾ ﻓﻴﻬﺎ ﻋﻴﻨﻴﻚ ﺑﺘﻔﻜﺮ ...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>يا ابو سلو عرفتني</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ب50 ريال أكفل معتمر في رمضان ، ولك بإذن الله م...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label\n",
       "0  يا من أناديها ويخنقني البكاء  ويكاد صمت الدمع ...    ar\n",
       "1  فيه فرق بين اهل غزة اللى مطحونين من ناحيتين وب...    ar\n",
       "2  ﻋﻦ ﺍﻟﻠﺤﻈﺔ اﻟﺤﻠﻮﺓﺓ ﺍﻟﻠﻲ ﺑﺘﻐﻤﺾ ﻓﻴﻬﺎ ﻋﻴﻨﻴﻚ ﺑﺘﻔﻜﺮ ...    ar\n",
       "3                                  يا ابو سلو عرفتني    ar\n",
       "4  ب50 ريال أكفل معتمر في رمضان ، ولك بإذن الله م...    ar"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "p-K1HUEordhz",
    "outputId": "f6c169bf-32da-4cd1-8d66-824c862af9bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ar' 'ar_LATN' 'az' 'bg' 'bn' 'bs' 'ca' 'cs' 'cy' 'da' 'de' 'dv' 'el'\n",
      " 'en' 'es' 'et' 'fa' 'fi' 'fr' 'gl' 'ha' 'he' 'hi' 'hi-Latn' 'hr' 'ht'\n",
      " 'hu' 'hy' 'id' 'is' 'it' 'ja' 'ja_LATN' 'jv' 'km' 'ko' 'ko_LATN' 'ms'\n",
      " 'ne' 'nl' 'no' 'pl' 'ps' 'ps_LATN' 'pt' 'ro' 'ru' 'si' 'sl' 'sq' 'sr'\n",
      " 'su' 'sv' 'sw' 'ta' 'ta_LATN' 'th' 'tl' 'tn' 'tr' 'uk' 'und' 'ur'\n",
      " 'ur_LATN' 'vi' 'wo' 'xh' 'zh-CN' 'zh-TW']\n"
     ]
    }
   ],
   "source": [
    "print(df_train_dev.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "mok54OinmXQw",
    "outputId": "1890b90e-5074-457b-9828-426b4485fc18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6e81be2c50>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_dev.groupby('label').size().sort_values(ascending = False).plot.bar(figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "id": "3f24YMQAz44u",
    "outputId": "920f876c-0494-4221-fd2c-85577c5056c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "en         18508\n",
       "ja         10421\n",
       "es          5930\n",
       "und         4537\n",
       "id          3006\n",
       "           ...  \n",
       "dv             1\n",
       "tn             1\n",
       "ta_LATN        1\n",
       "si             1\n",
       "ja_LATN        1\n",
       "Length: 69, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dev.groupby('label').size().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHJz9Unop3tN"
   },
   "source": [
    "# Deal with class imbalance by unifying very rare classes (1 member) and upsampling rare classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 650,
     "status": "ok",
     "timestamp": 1606833819265,
     "user": {
      "displayName": "David Stalder",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgsijLpQ4SIyqjTTwo8axfuAd0nTgHsTIdHbhLpSQ=s64",
      "userId": "06489165530893587391"
     },
     "user_tz": -60
    },
    "id": "8dBdrBI_d6pD"
   },
   "outputs": [],
   "source": [
    "# df_train_dev['label'] = df_train_dev['label'].apply(lambda x: x.strip().lower())\n",
    "# df_test['label'] = df_test['label'].apply(lambda x: x.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "executionInfo": {
     "elapsed": 535,
     "status": "error",
     "timestamp": 1606833821310,
     "user": {
      "displayName": "David Stalder",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgsijLpQ4SIyqjTTwo8axfuAd0nTgHsTIdHbhLpSQ=s64",
      "userId": "06489165530893587391"
     },
     "user_tz": -60
    },
    "id": "-KSwSCy_OY_r",
    "outputId": "edfc16e6-23af-47f2-e063-b62b1690c182"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-01605f5722e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf_train_dev_uni\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munify_singleton_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train_dev' is not defined"
     ]
    }
   ],
   "source": [
    "def unify_singleton_classes(df, threshold):\n",
    "    counts = df['label'].value_counts()\n",
    "    rare_labels = [label for label in counts[counts < threshold].index]\n",
    "    df.loc[(df.label.isin(rare_labels)), 'label'] = 'und'\n",
    "    return df\n",
    "\n",
    "df_train_dev_uni = unify_singleton_classes(df_train_dev, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "executionInfo": {
     "elapsed": 1066,
     "status": "error",
     "timestamp": 1606833810872,
     "user": {
      "displayName": "David Stalder",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgsijLpQ4SIyqjTTwo8axfuAd0nTgHsTIdHbhLpSQ=s64",
      "userId": "06489165530893587391"
     },
     "user_tz": -60
    },
    "id": "XdSkUrZueMU1",
    "outputId": "7bbcab0e-b395-4c01-8722-cb6473cdcfbf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f20282898d22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupsampled_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdf_train_dev_up\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupsample_rare_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train_dev_uni\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train_dev_uni' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def upsample_rare_classes(df, threshold, sample_size):\n",
    "    \"\"\"Copy low frequent Tweets of languages, that have a number \n",
    "    of tweets below a certain threshold.\n",
    "    \n",
    "    :param data_train: dataframe\n",
    "    :param threshold: int\n",
    "    :param sample_size: int\n",
    "    \"\"\"\n",
    "    class_counts = defaultdict(int)\n",
    "    classes_to_upsample = set()\n",
    "    for index, row in df.iterrows():\n",
    "        class_counts[row['label']] += 1\n",
    "    for label, count in class_counts.items():\n",
    "        if count < threshold:\n",
    "            classes_to_upsample.add(label)\n",
    "    df_to_upsample = df[df['label'].isin(classes_to_upsample)]\n",
    "    upsampled_classes = pd.DataFrame(resample(df_to_upsample.to_numpy(), replace=True, n_samples=sample_size, random_state=42))\n",
    "    upsampled_classes.columns = ['tweet', 'label']\n",
    "    return pd.concat([df, upsampled_classes]).sample(frac=1)\n",
    "\n",
    "df_train_dev_up = upsample_rare_classes(df=df_train_dev_uni, threshold=50, sample_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "Yg7Ot2RWeVHj",
    "outputId": "a214b182-191c-488e-bc14-03ace4c494a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52675, 2)\n",
      "(54675, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_train_dev.shape)\n",
    "print(df_train_dev_up.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qxb9qeRprB8"
   },
   "source": [
    "# Process labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8FwgxNUdngK1"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_fitted = LabelEncoder().fit(df_train_dev_up['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "2V6JkOLrn-75",
    "outputId": "c27753ea-fd1e-492e-c637-dbbbbdefca32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# map all classes that are not in train_dev to undefined\n",
    "for i, label in enumerate(df_test['label']):\n",
    "    df_test['label'][i] = 'und' if label not in le_fitted.classes_ else label\n",
    "# check if it worked: should return an empty list\n",
    "print([label for label in df_test['label'] if label not in set(df_train_dev_up['label'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EV6KmRn4oOIF"
   },
   "outputs": [],
   "source": [
    "y_train_dev, y_test = le_fitted.transform(df_train_dev_up['label']), le_fitted.transform(df_test['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0gShv_UsLiZ"
   },
   "source": [
    "# Preprocess Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93UMrd5BtL-B"
   },
   "source": [
    "Pipeline classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6iOls7ib_-H"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "class TweetNormalizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "\n",
    "    def _normalize_tweet(self, tweet):\n",
    "        \"\"\"Remove punctuation and newlines, lowercase, pad with spaces.\n",
    "\n",
    "        :param tweet: string\n",
    "        :return: normalized string\n",
    "        \"\"\"\n",
    "        tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "        tweet = re.sub(r'\\n', r'', tweet)\n",
    "        tweet = tweet.lower()\n",
    "        tweet = re.sub(r'@\\w+\\b', r'', tweet)\n",
    "        tweet = re.sub(r'\\b\\S+//\\S+\\b', r'', tweet)\n",
    "        # tweet = ' ' + tweet + ' '\n",
    "        return tweet\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        tweets = []\n",
    "        for tweet in X:\n",
    "            tweets.append(self._normalize_tweet(tweet))\n",
    "        return np.array(tweets)\n",
    "\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "\n",
    "    vowels = set([c for c in 'aeiouäöüàéèëï'])\n",
    "    consonants = set([c for c in 'bcdfghklmnlpqrstvwxyz'])\n",
    "\n",
    "    def __init__(self):\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def _to_bigrams(self, tweet):\n",
    "        return [bg[0] + bg[1] for bg in zip(tweet, tweet[1:])]\n",
    "\n",
    "    def _get_vowel_consonant_ratio(self, tweet):\n",
    "        vf = 0\n",
    "        cf = 0\n",
    "        for c in tweet.lower():\n",
    "            if c in self.vowels:\n",
    "                vf =+ 1\n",
    "            elif c in self.consonants:\n",
    "                cf += 1\n",
    "        return vf / (cf + 1)\n",
    "\n",
    "    def _get_capitalization_ratio(self, tweet):\n",
    "        up_count = 0\n",
    "        for c in tweet:\n",
    "            if c.upper() == c:\n",
    "                up_count += 1\n",
    "        return up_count / (len(tweet) + 1)\n",
    "\n",
    "    def _get_double_char_freq(self, tweet):\n",
    "        double_freq = 0\n",
    "        for bg in self._to_bigrams(tweet):\n",
    "            if bg[0] == bg[1]:\n",
    "                double_freq += 1\n",
    "        return double_freq\n",
    "    \n",
    "    def _extract_num_features(self, tweets):\n",
    "        num_features = []\n",
    "        for tweet in tweets:\n",
    "            feat_tweet = []\n",
    "            feat_tweet.append(self._get_vowel_consonant_ratio(tweet))\n",
    "            feat_tweet.append(self._get_capitalization_ratio(tweet))\n",
    "            feat_tweet.append(self._get_double_char_freq(tweet))\n",
    "            num_features.append(feat_tweet)\n",
    "        return np.array(num_features)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        numerical_features = self._extract_num_features(X)\n",
    "        self.scaler.fit(numerical_features)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        numerical_features= self._extract_num_features(X)\n",
    "        return X, self.scaler.transform(numerical_features)\n",
    "\n",
    "\n",
    "class MatrixToArrayConverter1(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[0].toarray(), X[1]\n",
    "\n",
    "\n",
    "class MatrixUnifier(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return np.concatenate([X[0].todense(), X[1]], axis=1)\n",
    "\n",
    "\n",
    "class CountVectorizerWrapper:\n",
    "\n",
    "    def __init__(self, ngram_range, analyzer, max_features, binary):\n",
    "        print('args:', str([ngram_range, analyzer, max_features, binary]))\n",
    "        self.countvec = CountVectorizer(ngram_range=ngram_range, analyzer=analyzer, max_features=max_features, binary=binary)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        tweets, numerical_features = X\n",
    "        self.countvec.fit(tweets)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        tweets, numerical_features = X\n",
    "        return self.countvec.transform(tweets), numerical_features\n",
    "\n",
    "\n",
    "class OneHotEncoderWrapper:\n",
    "\n",
    "    def __init__(self, handle_unknown):\n",
    "        self.ohe = OneHotEncoder(handle_unknown=handle_unknown)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.ohe.fit(X[0])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.ohe.transform(X[0]), X[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3gvmuUPtS5j"
   },
   "source": [
    "Helper classes for the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asuv2Ey8suTF"
   },
   "outputs": [],
   "source": [
    "class GenericClassifier(BaseEstimator):\n",
    "\n",
    "    def __init__(self, estimator):\n",
    "        self.clf = clf\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.clf.fit(X, y)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)\n",
    "\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.clf.score(X, y)\n",
    "\n",
    "\n",
    "class Debug(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def transform(self, X):\n",
    "        import pdb; pdb.set_trace()\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yerRC06qtabm"
   },
   "source": [
    "# GridSearch and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQq5eigQKi2D"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pDxK9slayq3"
   },
   "outputs": [],
   "source": [
    "clf_param_grid = {\n",
    "    'MultinomialNB': [MultinomialNB, {'CLF__alpha': [0.1, 1]}],\n",
    "    'SGDClassifier': [SGDClassifier, {'CLF__loss': ['hinge', 'log'], 'CLF__penalty': ['l2', 'l1'], 'CLF__max_iter': [100, 300], 'CLF__early_stopping': [True, False]}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YOsRd7OoFUWn",
    "outputId": "2f779dba-5fe8-4979-d680-f579fd4f02a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "MultinomialNB\n",
      "{'CLF__alpha': [0.1, 1]}\n",
      "args: [(2, 2), 'char_wb', 100, True]\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   2.4s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.4s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.3s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.8s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   8.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.8s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   2.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.8s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.3s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.4s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.4s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   6.3s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   8.4s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.7s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.1s\n",
      "------------------------------\n",
      "SGDClassifier\n",
      "{'CLF__loss': ['hinge', 'log'], 'CLF__penalty': ['l2', 'l1'], 'CLF__max_iter': [100, 300], 'CLF__early_stopping': [True, False]}\n",
      "args: [(2, 2), 'char_wb', 100, True]\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  20.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.8s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  20.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.2s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  21.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  19.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  20.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  19.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  19.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  19.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  19.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  20.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   9.9s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  35.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  35.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.0s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.3s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  35.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  35.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  35.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.8s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.7s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  36.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  35.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  35.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  35.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  34.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  19.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  20.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.5s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.4s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  20.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   8.0s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   8.1s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  19.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  19.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  19.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  19.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  19.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  19.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  19.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  35.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  34.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.2s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  35.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  34.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  34.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  34.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  35.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   6.0s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=  11.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  35.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  34.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  34.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  27.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  27.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.3s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  28.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  27.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.8s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   8.0s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  27.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  27.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  27.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  27.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  27.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  27.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  47.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.8s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  45.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  46.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  45.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  46.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  46.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  45.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  45.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  45.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  45.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  32.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  27.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  29.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  27.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  27.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  27.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  27.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  27.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  27.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  28.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  45.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  45.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.0s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.3s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  46.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  48.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  45.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  45.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  45.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  45.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  45.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  45.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  25.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  25.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.0s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.3s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  29.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  25.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  27.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.9s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  25.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  25.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  25.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  25.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  24.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.0min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.0min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.0s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.3s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.1min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   8.1s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.1min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.3s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.0min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.6s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   7.9s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  59.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.1min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.3s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.1min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  57.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.4s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.0min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.3s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  26.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.3s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.9s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  25.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.0s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.3s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  28.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  24.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  25.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  26.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  25.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  26.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  25.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  24.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.0min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.0min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.0s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.2s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.1min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.5s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.0min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  59.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.1min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  59.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.0min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.1min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.1min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  28.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  29.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.2s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  30.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  29.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  29.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  30.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  29.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  28.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  28.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  29.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.4min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.8s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.4min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.3s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.4min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.5min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.4min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.3min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.3min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.3min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.3s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.4min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.4min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.3s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  28.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.6s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   6.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  29.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.5s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  31.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  29.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  29.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  28.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  28.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  29.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  29.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   6.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  28.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.4min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.4min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   8.9s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.4min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.4min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.5min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.4min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.7s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.4min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.3min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=  10.2s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.4min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total= 1.3min\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.5s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   6.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   8.4s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.6s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  32.3s\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for clf_name in clf_param_grid:\n",
    "    print(30*'-')\n",
    "    print(clf_name)\n",
    "    param_grid = clf_param_grid[clf_name][1]\n",
    "    print(param_grid)\n",
    "    bigram_vec_args = dict(ngram_range=(2,2), analyzer='char_wb', max_features=100, binary=True)\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('TweetNormalizer', TweetNormalizer()),\n",
    "        ('FeatureExtractor', FeatureExtractor()),\n",
    "        ('BigramVectorizer', CountVectorizerWrapper(**bigram_vec_args)),\n",
    "        ('MatrixToArrayConverter', MatrixToArrayConverter1()),\n",
    "        ('OneHotEncoder', OneHotEncoderWrapper(handle_unknown='ignore')),\n",
    "        ('MatrixUnifier', MatrixUnifier()),\n",
    "        ('CLF', clf_param_grid[clf_name][0]())\n",
    "    ], verbose=True)\n",
    "    grid = GridSearchCV(pipe, n_jobs=1, param_grid=param_grid, scoring='f1_micro', cv=10)\n",
    "    grid.fit(df_train_dev_up['tweet'].to_numpy(), y_train_dev)\n",
    "    models.append(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aA3JAYJBDZxy"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZHDby7NB7PW"
   },
   "source": [
    "Micro f1-Score of the naive base models on the dev set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "gDOlBtb2B4Nq",
    "outputId": "815a55cc-d51b-4f6a-857a-52702b285552"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([15.36567056, 14.83670509]),\n",
       " 'mean_score_time': array([0.76010673, 0.68476903]),\n",
       " 'mean_test_score': array([0.61991759, 0.61781428]),\n",
       " 'param_CLF__alpha': masked_array(data=[0.1, 1],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'CLF__alpha': 0.1}, {'CLF__alpha': 1}],\n",
       " 'rank_test_score': array([1, 2], dtype=int32),\n",
       " 'split0_test_score': array([0.60442575, 0.60259693]),\n",
       " 'split1_test_score': array([0.62746891, 0.62692026]),\n",
       " 'split2_test_score': array([0.62070227, 0.61795903]),\n",
       " 'split3_test_score': array([0.61942209, 0.61558157]),\n",
       " 'split4_test_score': array([0.63332114, 0.63039503]),\n",
       " 'split5_test_score': array([0.62301079, 0.6184379 ]),\n",
       " 'split6_test_score': array([0.62173038, 0.6208158 ]),\n",
       " 'split7_test_score': array([0.6067313 , 0.60837754]),\n",
       " 'split8_test_score': array([0.62118164, 0.61916956]),\n",
       " 'split9_test_score': array([0.62118164, 0.61788915]),\n",
       " 'std_fit_time': array([1.20570028, 0.84751295]),\n",
       " 'std_score_time': array([0.25254022, 0.1070639 ]),\n",
       " 'std_test_score': array([0.00816985, 0.00760303])}"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0].cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcqrfTK1Bcxd"
   },
   "source": [
    "Micro and macro f1-score of the best naive bayes model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "eIlAIaVnNHOU",
    "outputId": "c2b2e76a-c91f-4520-d78d-64ddc65f44e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-micro-score on the testset: 0.6298667068303336\n",
      "F1-macro-score on the testset: 0.1891293449074721\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "preds = models[0].predict(df_test['tweet'].to_numpy())\n",
    "f1_micro = f1_score(preds, y_test, average='micro')\n",
    "f1_macro = f1_score(preds, y_test, average='macro')\n",
    "print(f'F1-micro-score on the testset: {f1_micro}')\n",
    "print(f'F1-macro-score on the testset: {f1_macro}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RKO1bbsCDne"
   },
   "source": [
    "Micro f1-Score of the SGD models on the dev set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FW-5WG9SBzyU",
    "outputId": "3fe3382c-e5fe-436f-bdb5-3ab471e21fc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([34.92653723, 50.45851586, 34.84295452, 50.16186893, 42.44045622,\n",
       "        60.79770355, 43.09442978, 60.35572217, 40.88421643, 77.39089243,\n",
       "        40.50925915, 77.24433172, 44.00839155, 97.71396422, 44.11117506,\n",
       "        99.27012889]),\n",
       " 'mean_score_time': array([0.69382052, 0.6921206 , 0.69145575, 0.68961115, 0.69149637,\n",
       "        0.68872337, 0.69514825, 0.69482107, 0.64930549, 0.64660978,\n",
       "        0.64958162, 0.64531262, 0.64991169, 0.65115962, 0.68658216,\n",
       "        0.64630191]),\n",
       " 'mean_test_score': array([0.66738063, 0.66610009, 0.6451774 , 0.68347514, 0.68642086,\n",
       "        0.69964359, 0.6872975 , 0.69651563, 0.72418882, 0.71564712,\n",
       "        0.71487943, 0.71253834, 0.74015567, 0.73256524, 0.74222244,\n",
       "        0.73093762]),\n",
       " 'param_CLF__early_stopping': masked_array(data=[True, True, True, True, True, True, True, True, False,\n",
       "                    False, False, False, False, False, False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_CLF__loss': masked_array(data=['hinge', 'hinge', 'hinge', 'hinge', 'log', 'log',\n",
       "                    'log', 'log', 'hinge', 'hinge', 'hinge', 'hinge',\n",
       "                    'log', 'log', 'log', 'log'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_CLF__max_iter': masked_array(data=[100, 100, 300, 300, 100, 100, 300, 300, 100, 100, 300,\n",
       "                    300, 100, 100, 300, 300],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_CLF__penalty': masked_array(data=['l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l1'}],\n",
       " 'rank_test_score': array([14, 15, 16, 13, 12,  9, 11, 10,  5,  6,  7,  8,  2,  3,  1,  4],\n",
       "       dtype=int32),\n",
       " 'split0_test_score': array([0.6183248 , 0.69952451, 0.52011704, 0.67483541, 0.70903438,\n",
       "        0.6861741 , 0.68215069, 0.69092904, 0.7222019 , 0.7108632 ,\n",
       "        0.71122897, 0.71013168, 0.73994148, 0.72823702, 0.7355523 ,\n",
       "        0.72604243]),\n",
       " 'split1_test_score': array([0.65069495, 0.55120702, 0.68855157, 0.67959034, 0.55705925,\n",
       "        0.6841624 , 0.7088515 , 0.6923921 , 0.70647403, 0.71013168,\n",
       "        0.68964887, 0.69568398, 0.74323336, 0.72421361, 0.73317484,\n",
       "        0.72933431]),\n",
       " 'split2_test_score': array([0.63588149, 0.69531822, 0.67337235, 0.66386247, 0.6790417 ,\n",
       "        0.70446233, 0.63423555, 0.71689832, 0.71488661, 0.72110461,\n",
       "        0.70866862, 0.69678127, 0.74652524, 0.73500366, 0.74542794,\n",
       "        0.7284199 ]),\n",
       " 'split3_test_score': array([0.68818581, 0.66075347, 0.59070958, 0.68800293, 0.70519386,\n",
       "        0.6955011 , 0.70994879, 0.6923921 , 0.72457937, 0.71342356,\n",
       "        0.70720556, 0.70830285, 0.72128749, 0.72768837, 0.73957571,\n",
       "        0.72055596]),\n",
       " 'split4_test_score': array([0.70793709, 0.70135333, 0.6790417 , 0.70793709, 0.72110461,\n",
       "        0.71452085, 0.71031456, 0.69787857, 0.72896854, 0.71616679,\n",
       "        0.72476225, 0.71817849, 0.73847842, 0.74305048, 0.74561083,\n",
       "        0.73573519]),\n",
       " 'split5_test_score': array([0.62410829, 0.63910737, 0.661606  , 0.67934882, 0.69032376,\n",
       "        0.71044449, 0.69014085, 0.70404244, 0.72379733, 0.71666362,\n",
       "        0.71391988, 0.70971282, 0.7409914 , 0.73056521, 0.74263764,\n",
       "        0.72837022]),\n",
       " 'split6_test_score': array([0.71739528, 0.69654289, 0.68538504, 0.67495884, 0.71263947,\n",
       "        0.68410463, 0.66599598, 0.67130053, 0.73751601, 0.72507774,\n",
       "        0.71849277, 0.7023962 , 0.73916225, 0.73330894, 0.74721054,\n",
       "        0.73385769]),\n",
       " 'split7_test_score': array([0.71117615, 0.64441193, 0.64477776, 0.69270166, 0.72160234,\n",
       "        0.70916408, 0.7234315 , 0.69946954, 0.73239437, 0.71263947,\n",
       "        0.73440644, 0.72654106, 0.73733309, 0.72983355, 0.74318639,\n",
       "        0.73897933]),\n",
       " 'split8_test_score': array([0.68117798, 0.68977501, 0.61002378, 0.69416499, 0.68319005,\n",
       "        0.69087251, 0.71959027, 0.70001829, 0.71959027, 0.72434608,\n",
       "        0.70550576, 0.72891897, 0.74611304, 0.73879641, 0.7362356 ,\n",
       "        0.73916225]),\n",
       " 'split9_test_score': array([0.63892446, 0.68300713, 0.69818913, 0.67934882, 0.68501921,\n",
       "        0.71702945, 0.62831535, 0.69983538, 0.73147979, 0.70605451,\n",
       "        0.73495519, 0.72873605, 0.74849095, 0.73495519, 0.75361258,\n",
       "        0.72891897]),\n",
       " 'std_fit_time': array([0.7379432 , 1.29625743, 1.02987674, 1.67393651, 0.55707438,\n",
       "        1.01814217, 1.33705735, 1.04640906, 0.76931572, 1.85312842,\n",
       "        0.58493873, 2.00378556, 0.71446148, 2.95931375, 0.67016561,\n",
       "        3.08698499]),\n",
       " 'std_score_time': array([0.09732691, 0.10484591, 0.10609186, 0.10281508, 0.1011397 ,\n",
       "        0.09828363, 0.09932801, 0.10325864, 0.10246187, 0.10003031,\n",
       "        0.10741654, 0.10234828, 0.10407675, 0.10171955, 0.13216155,\n",
       "        0.10300016]),\n",
       " 'std_test_score': array([0.03612048, 0.04406221, 0.05325658, 0.01182905, 0.04561625,\n",
       "        0.01229132, 0.03261706, 0.01098634, 0.00864115, 0.00595827,\n",
       "        0.01315759, 0.01193948, 0.00723554, 0.0053358 , 0.00588788,\n",
       "        0.00561404])}"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[1].cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlY-SAdYBmty"
   },
   "source": [
    "Accuracy of the best SGD model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "PEm-z0w3NiBf",
    "outputId": "37353758-7c1f-4d52-acd5-26c7787c096a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-micro-score on the testset: 0.768054823405377\n",
      "F1-macro-score on the testset: 0.23793764312477245\n"
     ]
    }
   ],
   "source": [
    "preds = models[1].predict(df_test['tweet'].to_numpy())\n",
    "f1_micro = f1_score(preds, y_test, average='micro')\n",
    "f1_macro = f1_score(preds, y_test, average='macro')\n",
    "print(f'F1-micro-score on the testset: {f1_micro}')\n",
    "print(f'F1-macro-score on the testset: {f1_macro}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kqDIw95Nsr2"
   },
   "source": [
    "Let's check the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Xeb6jHmeAeVK",
    "outputId": "b1ac50c4-4181-4a85-c66a-846b7c4016c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ar</th>\n",
       "      <th>ar_LATN</th>\n",
       "      <th>bn</th>\n",
       "      <th>bs</th>\n",
       "      <th>ca</th>\n",
       "      <th>cs</th>\n",
       "      <th>da</th>\n",
       "      <th>de</th>\n",
       "      <th>el</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>fa</th>\n",
       "      <th>fi</th>\n",
       "      <th>fr</th>\n",
       "      <th>gl</th>\n",
       "      <th>he</th>\n",
       "      <th>hi</th>\n",
       "      <th>hi-Latn</th>\n",
       "      <th>hr</th>\n",
       "      <th>hu</th>\n",
       "      <th>id</th>\n",
       "      <th>it</th>\n",
       "      <th>ja</th>\n",
       "      <th>jv</th>\n",
       "      <th>ko</th>\n",
       "      <th>ms</th>\n",
       "      <th>ne</th>\n",
       "      <th>nl</th>\n",
       "      <th>no</th>\n",
       "      <th>pl</th>\n",
       "      <th>pt</th>\n",
       "      <th>ro</th>\n",
       "      <th>ru</th>\n",
       "      <th>sq</th>\n",
       "      <th>sr</th>\n",
       "      <th>su</th>\n",
       "      <th>sv</th>\n",
       "      <th>sw</th>\n",
       "      <th>ta</th>\n",
       "      <th>th</th>\n",
       "      <th>tl</th>\n",
       "      <th>tr</th>\n",
       "      <th>uk</th>\n",
       "      <th>und</th>\n",
       "      <th>ur</th>\n",
       "      <th>ur_LATN</th>\n",
       "      <th>vi</th>\n",
       "      <th>zh-CN</th>\n",
       "      <th>zh-TW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ar</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ar_LATN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bn</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bs</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4403</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>1219</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fi</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi-Latn</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hu</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>635</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ja</th>\n",
       "      <td>319</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2157</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jv</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ko</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ms</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ne</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>466</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ro</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sq</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sr</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>su</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sw</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ta</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>th</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>und</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>143</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>612</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ur</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ur_LATN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vi</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zh-CN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zh-TW</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ar  ar_LATN  bn  bs  ca  cs  ...  und  ur  ur_LATN  vi  zh-CN  zh-TW\n",
       "ar       203        1   0   0   0   0  ...   11   1        0   0      0      3\n",
       "ar_LATN    0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "bn         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "bs         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "ca         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "cs         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "da         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "de         0        0   0   0   0   0  ...    1   0        0   0      0      0\n",
       "el         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "en         3        2   0   0   1   0  ...  238   1        1   1      0      0\n",
       "es         0        0   0   0   2   0  ...   64   0        0   0      0      0\n",
       "fa         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "fi         0        0   0   0   0   0  ...    1   0        0   0      0      0\n",
       "fr         0        0   0   0   0   0  ...   13   0        0   0      0      0\n",
       "gl         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "he         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "hi         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "hi-Latn    0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "hr         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "hu         0        0   0   0   0   0  ...    2   0        0   0      0      0\n",
       "id         0        0   0   0   0   0  ...   75   0        0   3      0      0\n",
       "it         0        0   0   0   0   0  ...    4   0        0   0      0      0\n",
       "ja       319        0   0   0   0   0  ...  154   3        0   0      1      1\n",
       "jv         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "ko         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "ms         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "ne         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "nl         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "no         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "pl         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "pt         0        0   0   0   0   1  ...   16   0        0   0      0      0\n",
       "ro         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "ru         0        0   0   0   0   0  ...   34   0        0   0      0      0\n",
       "sq         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "sr         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "su         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "sv         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "sw         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "ta         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "th         0        0   0   0   0   0  ...    6   0        0   0      0      0\n",
       "tl         0        0   0   0   0   0  ...    1   0        0   0      0      0\n",
       "tr         0        0   0   0   0   0  ...   18   0        0   0      0      0\n",
       "uk         0        0   0   0   0   0  ...    1   0        0   0      0      0\n",
       "und        3        0   0   1   0   0  ...  612   0        0   0      0      0\n",
       "ur         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "ur_LATN    0        0   0   0   0   0  ...    2   0        0   0      0      0\n",
       "vi         0        0   0   0   0   0  ...    0   0        0   1      0      0\n",
       "zh-CN      0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "zh-TW      1        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "\n",
       "[49 rows x 49 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(le_fitted.classes_)\n",
    "def create_confusion_matrix(num_classes, preds, y_test):\n",
    "    \"\"\"Create confusion matrix 'by hand' since test set does not contain all labels (thanks to Sarah Kiener).\"\"\"\n",
    "    df = pd.DataFrame(np.zeros((num_classes, num_classes), dtype=int))\n",
    "    for i, j in zip(preds, y_test):\n",
    "        df.iloc[i, j] += 1\n",
    "    df.columns = le_fitted.classes_\n",
    "    df.index = le_fitted.classes_\n",
    "    return df\n",
    "df = create_confusion_matrix(num_classes, preds, y_test)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Kopie von ex01_lc.ipynb",
   "provenance": [
    {
     "file_id": "1gMgoPaqApxDro2Wpdak-11lF1cF54waK",
     "timestamp": 1606832901736
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
