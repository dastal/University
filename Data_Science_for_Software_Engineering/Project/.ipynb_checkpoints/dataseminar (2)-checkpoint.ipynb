{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UgM7VEXCdbTX",
    "outputId": "6ca49fae-5c92-4bff-a527-7c3facbc3ab5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8c9529355705>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1BTTm7E7hz51"
   },
   "outputs": [],
   "source": [
    "url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRyox4OrcYQn5pZ8xKVXEHGkwOxmnDXY5jWgEsBPjAyYniIcJeSz8kcsGfDQirXK5LPn2Y-Y9iVZF4c/pub?gid=359064029&single=true&output=tsv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEtmPp7epxEZ"
   },
   "source": [
    "# Load and inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gYp_1Kmqt5W"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "foL-QtlJItoR"
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import requests\n",
    "r = requests.get(url)\n",
    "data = r.content.decode('utf8')\n",
    "X = pd.read_csv(StringIO(data), sep = '\\t')\n",
    "\n",
    "X.columns= ['bug-id', 'bug', 'label']\n",
    "X.dropna(subset=['label'], inplace=True)\n",
    "\n",
    "N = 10000\n",
    "Ntrain = int(0.8 * N)\n",
    "shuffler = np.random.permutation(N)\n",
    "x_data = X['bug']\n",
    "y_data = X['label']\n",
    "Xlist = np.array(x_data) \n",
    "Ylist = np.array(y_data)\n",
    "Xtrain = Xlist[shuffler[:Ntrain]]\n",
    "ytrain = Ylist[shuffler[:Ntrain]]\n",
    "Xtest = Xlist[shuffler[Ntrain:]]\n",
    "ytest = Ylist[shuffler[Ntrain:]]\n",
    "columns = ['bug','label']\n",
    "\n",
    "df_train_dev = pd.DataFrame({\"bug\": Xtrain, \"label\": ytrain})\n",
    "df_test = pd.DataFrame({\"bug\": Xtest, \"label\": ytest})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWTvXPPgiDzU",
    "outputId": "6f4bd01b-219d-47ea-9ca5-be5425ac362e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infos train-dev-set:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   bug     8000 non-null   object\n",
      " 1   label   8000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 125.1+ KB\n",
      "None\n",
      "Infos test-set:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   bug     2000 non-null   object\n",
      " 1   label   2000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Infos train-dev-set:')\n",
    "print(df_train_dev.info())\n",
    "print('Infos test-set:')\n",
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "h8lCjkb_kSOp",
    "outputId": "38e0c96d-c974-4686-97d3-bb2947beaad9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bug</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLOCKER: cannot insert cursor!</td>\n",
       "      <td>blocker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cannot build old Windows SDKs since Bug 830347</td>\n",
       "      <td>blocker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>need menubutton widget for smaller menu buttons</td>\n",
       "      <td>major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>incorrect nsRect usages</td>\n",
       "      <td>major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private browsing cache test leaves directories...</td>\n",
       "      <td>minor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 bug    label\n",
       "0                     BLOCKER: cannot insert cursor!  blocker\n",
       "1     Cannot build old Windows SDKs since Bug 830347  blocker\n",
       "2    need menubutton widget for smaller menu buttons    major\n",
       "3                            incorrect nsRect usages    major\n",
       "4  Private browsing cache test leaves directories...    minor"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-K1HUEordhz",
    "outputId": "d945bd95-8fac-42a9-f3ad-56136a90e5ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blocker' 'major' 'minor' 'critical' 'trivial' 'normal']\n"
     ]
    }
   ],
   "source": [
    "print(df_train_dev.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "mok54OinmXQw",
    "outputId": "ef152e99-9fee-49e3-bd48-5fbf63f6b355"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a26874deb8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dev.groupby('label').size().sort_values(ascending = False).plot.bar(figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f24YMQAz44u",
    "outputId": "371cbf25-665c-4443-a1db-eb80a2fb631b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "normal      1570\n",
       "critical    1557\n",
       "blocker     1528\n",
       "major       1512\n",
       "minor       1402\n",
       "trivial      431\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dev.groupby('label').size().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qxb9qeRprB8"
   },
   "source": [
    "# Process labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8FwgxNUdngK1"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_fitted = LabelEncoder().fit(df_train_dev['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2V6JkOLrn-75",
    "outputId": "3610b9f1-cc37-48b5-e190-3b07703533fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# map all classes that are not in train_dev to undefined\n",
    "for i, label in enumerate(df_test['label']):\n",
    "    df_test['label'][i] = 'und' if label not in le_fitted.classes_ else label\n",
    "# check if it worked: should return an empty list\n",
    "print([label for label in df_test['label'] if label not in set(df_train_dev['label'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4mGBukF1Dzu",
    "outputId": "765c8f37-8ff9-449c-b4ca-6f1a16a72e52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      normal\n",
       "1     blocker\n",
       "2       minor\n",
       "3    critical\n",
       "4       major\n",
       "5     blocker\n",
       "6       minor\n",
       "7    critical\n",
       "8      normal\n",
       "9       minor\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dev['label'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "EV6KmRn4oOIF"
   },
   "outputs": [],
   "source": [
    "y_train_dev, y_test = le_fitted.transform(df_train_dev['label']), le_fitted.transform(df_test['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0gShv_UsLiZ"
   },
   "source": [
    "# Preprocess bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93UMrd5BtL-B"
   },
   "source": [
    "Pipeline classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "M6iOls7ib_-H"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "class TweetNormalizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "\n",
    "    def _normalize_tweet(self, tweet):\n",
    "        \"\"\"Remove punctuation and newlines, lowercase, pad with spaces.\n",
    "\n",
    "        :param tweet: string\n",
    "        :return: normalized string\n",
    "        \"\"\"\n",
    "        tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "        tweet = re.sub(r'\\n', r'', tweet)\n",
    "        tweet = tweet.lower()\n",
    "        tweet = re.sub(r'@\\w+\\b', r'', tweet)\n",
    "        tweet = re.sub(r'\\b\\S+//\\S+\\b', r'', tweet)\n",
    "        # tweet = ' ' + tweet + ' '\n",
    "        return tweet\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        tweets = []\n",
    "        for tweet in X:\n",
    "            tweets.append(self._normalize_tweet(tweet))\n",
    "        return np.array(tweets)\n",
    "\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "\n",
    "    vowels = set([c for c in 'aeiouäöüàéèëï'])\n",
    "    consonants = set([c for c in 'bcdfghklmnlpqrstvwxyz'])\n",
    "\n",
    "    def __init__(self):\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def _to_bigrams(self, tweet):\n",
    "        return [bg[0] + bg[1] for bg in zip(tweet, tweet[1:])]\n",
    "\n",
    "    def _get_vowel_consonant_ratio(self, tweet):\n",
    "        vf = 0\n",
    "        cf = 0\n",
    "        for c in tweet.lower():\n",
    "            if c in self.vowels:\n",
    "                vf =+ 1\n",
    "            elif c in self.consonants:\n",
    "                cf += 1\n",
    "        return vf / (cf + 1)\n",
    "\n",
    "    def _get_capitalization_ratio(self, tweet):\n",
    "        up_count = 0\n",
    "        for c in tweet:\n",
    "            if c.upper() == c:\n",
    "                up_count += 1\n",
    "        return up_count / (len(tweet) + 1)\n",
    "\n",
    "    def _get_double_char_freq(self, tweet):\n",
    "        double_freq = 0\n",
    "        for bg in self._to_bigrams(tweet):\n",
    "            if bg[0] == bg[1]:\n",
    "                double_freq += 1\n",
    "        return double_freq\n",
    "    \n",
    "    def _extract_num_features(self, tweets):\n",
    "        num_features = []\n",
    "        for tweet in tweets:\n",
    "            feat_tweet = []\n",
    "            feat_tweet.append(self._get_vowel_consonant_ratio(tweet))\n",
    "            feat_tweet.append(self._get_capitalization_ratio(tweet))\n",
    "            feat_tweet.append(self._get_double_char_freq(tweet))\n",
    "            num_features.append(feat_tweet)\n",
    "        return np.array(num_features)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        numerical_features = self._extract_num_features(X)\n",
    "        self.scaler.fit(numerical_features)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        numerical_features= self._extract_num_features(X)\n",
    "        return X, self.scaler.transform(numerical_features)\n",
    "\n",
    "\n",
    "class MatrixToArrayConverter1(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[0].toarray(), X[1]\n",
    "\n",
    "\n",
    "class MatrixUnifier(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return np.concatenate([X[0].todense(), X[1]], axis=1)\n",
    "\n",
    "\n",
    "class CountVectorizerWrapper:\n",
    "\n",
    "    def __init__(self, ngram_range, analyzer, max_features, binary):\n",
    "        print('args:', str([ngram_range, analyzer, max_features, binary]))\n",
    "        self.countvec = CountVectorizer(ngram_range=ngram_range, analyzer=analyzer, max_features=max_features, binary=binary)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        tweets, numerical_features = X\n",
    "        self.countvec.fit(tweets)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        tweets, numerical_features = X\n",
    "        return self.countvec.transform(tweets), numerical_features\n",
    "\n",
    "\n",
    "class OneHotEncoderWrapper:\n",
    "\n",
    "    def __init__(self, handle_unknown):\n",
    "        self.ohe = OneHotEncoder(handle_unknown=handle_unknown)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.ohe.fit(X[0])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.ohe.transform(X[0]), X[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3gvmuUPtS5j"
   },
   "source": [
    "Helper classes for the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "asuv2Ey8suTF"
   },
   "outputs": [],
   "source": [
    "class GenericClassifier(BaseEstimator):\n",
    "\n",
    "    def __init__(self, estimator):\n",
    "        self.clf = clf\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.clf.fit(X, y)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)\n",
    "\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.clf.score(X, y)\n",
    "\n",
    "\n",
    "class Debug(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def transform(self, X):\n",
    "        import pdb; pdb.set_trace()\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yerRC06qtabm"
   },
   "source": [
    "# GridSearch and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "uQq5eigQKi2D"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "4pDxK9slayq3"
   },
   "outputs": [],
   "source": [
    "clf_param_grid = {\n",
    "    'MultinomialNB': [MultinomialNB, {'CLF__alpha': [0.1, 1]}],\n",
    "    'SGDClassifier': [SGDClassifier, {'CLF__loss': ['hinge', 'log'], 'CLF__penalty': ['l2', 'l1'], 'CLF__max_iter': [100, 300], 'CLF__early_stopping': [True, False]}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YOsRd7OoFUWn",
    "outputId": "df427f5d-ec71-4670-f4f2-5fbba882e532"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "MultinomialNB\n",
      "{'CLF__alpha': [0.1, 1]}\n",
      "args: [(2, 2), 'char_wb', 100, True]\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.0s\n",
      "------------------------------\n",
      "SGDClassifier\n",
      "{'CLF__loss': ['hinge', 'log'], 'CLF__penalty': ['l2', 'l1'], 'CLF__max_iter': [100, 300], 'CLF__early_stopping': [True, False]}\n",
      "args: [(2, 2), 'char_wb', 100, True]\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.3s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.3s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.3s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.3s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   0.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   1.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   2.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   4.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   4.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   4.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   4.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   4.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   0.4s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   0.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.1s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for clf_name in clf_param_grid:\n",
    "    print(30*'-')\n",
    "    print(clf_name)\n",
    "    param_grid = clf_param_grid[clf_name][1]\n",
    "    print(param_grid)\n",
    "    bigram_vec_args = dict(ngram_range=(2,2), analyzer='char_wb', max_features=100, binary=True)\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('TweetNormalizer', TweetNormalizer()),\n",
    "        ('FeatureExtractor', FeatureExtractor()),\n",
    "        ('BigramVectorizer', CountVectorizerWrapper(**bigram_vec_args)),\n",
    "        ('MatrixToArrayConverter', MatrixToArrayConverter1()),\n",
    "        ('OneHotEncoder', OneHotEncoderWrapper(handle_unknown='ignore')),\n",
    "        ('MatrixUnifier', MatrixUnifier()),\n",
    "        ('CLF', clf_param_grid[clf_name][0]())\n",
    "    ], verbose=True)\n",
    "    grid = GridSearchCV(pipe, n_jobs=1, param_grid=param_grid, scoring='f1_micro', cv=10)\n",
    "    grid.fit(df_train_dev['bug'].to_numpy(), y_train_dev)\n",
    "    models.append(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aA3JAYJBDZxy"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZHDby7NB7PW"
   },
   "source": [
    "Micro f1-Score of the naive base models on the dev set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDOlBtb2B4Nq",
    "outputId": "0389548c-2721-41d4-dc94-2df01b8de92c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.12249234, 1.1144706 ]),\n",
       " 'mean_score_time': array([0.12933674, 0.12165906]),\n",
       " 'mean_test_score': array([0.72385714, 0.72357143]),\n",
       " 'param_CLF__alpha': masked_array(data=[0.1, 1],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'CLF__alpha': 0.1}, {'CLF__alpha': 1}],\n",
       " 'rank_test_score': array([1, 2], dtype=int32),\n",
       " 'split0_test_score': array([0.72714286, 0.72714286]),\n",
       " 'split1_test_score': array([0.72142857, 0.72142857]),\n",
       " 'split2_test_score': array([0.7       , 0.70142857]),\n",
       " 'split3_test_score': array([0.71571429, 0.71571429]),\n",
       " 'split4_test_score': array([0.72857143, 0.72857143]),\n",
       " 'split5_test_score': array([0.73285714, 0.73285714]),\n",
       " 'split6_test_score': array([0.71714286, 0.71714286]),\n",
       " 'split7_test_score': array([0.71714286, 0.71714286]),\n",
       " 'split8_test_score': array([0.73857143, 0.73714286]),\n",
       " 'split9_test_score': array([0.74      , 0.73714286]),\n",
       " 'std_fit_time': array([0.02722769, 0.01921792]),\n",
       " 'std_score_time': array([0.02204268, 0.00362002]),\n",
       " 'std_test_score': array([0.01150067, 0.01063782])}"
      ]
     },
     "execution_count": 127,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0].cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcqrfTK1Bcxd"
   },
   "source": [
    "Micro and macro f1-score of the best naive bayes model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIlAIaVnNHOU",
    "outputId": "a0323b54-78ef-42eb-c0b9-64f6e45ae3b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-micro-score on the testset: 0.8809683927370545\n",
      "F1-macro-score on the testset: 0.23417947801215588\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "preds = models[0].predict(df_test['bug'].to_numpy())\n",
    "f1_micro = f1_score(preds, y_test, average='micro')\n",
    "f1_macro = f1_score(preds, y_test, average='macro')\n",
    "print(f'F1-micro-score on the testset: {f1_micro}')\n",
    "print(f'F1-macro-score on the testset: {f1_macro}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RKO1bbsCDne"
   },
   "source": [
    "Micro f1-Score of the SGD models on the dev set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FW-5WG9SBzyU",
    "outputId": "e5bde2da-07eb-487c-99fd-9f1b0b3c40e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.3469048 , 1.56157084, 1.33405526, 1.59170597, 1.4405201 ,\n",
       "        1.72794034, 1.44879322, 1.713466  , 2.22032859, 3.28094015,\n",
       "        2.58390758, 3.05967634, 2.83111517, 4.57194583, 3.0159354 ,\n",
       "        4.27098441]),\n",
       " 'mean_score_time': array([0.12111337, 0.12070925, 0.12135096, 0.12362285, 0.12067373,\n",
       "        0.12134085, 0.12401848, 0.12226448, 0.06814857, 0.06908364,\n",
       "        0.06998861, 0.0694267 , 0.06960695, 0.0790782 , 0.06847961,\n",
       "        0.06860471]),\n",
       " 'mean_test_score': array([0.65785714, 0.67328571, 0.67057143, 0.69542857, 0.65142857,\n",
       "        0.65142857, 0.63114286, 0.61928571, 0.72014286, 0.69928571,\n",
       "        0.71814286, 0.69571429, 0.713     , 0.72585714, 0.71357143,\n",
       "        0.71228571]),\n",
       " 'param_CLF__early_stopping': masked_array(data=[True, True, True, True, True, True, True, True, False,\n",
       "                    False, False, False, False, False, False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_CLF__loss': masked_array(data=['hinge', 'hinge', 'hinge', 'hinge', 'log', 'log',\n",
       "                    'log', 'log', 'hinge', 'hinge', 'hinge', 'hinge',\n",
       "                    'log', 'log', 'log', 'log'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_CLF__max_iter': masked_array(data=[100, 100, 300, 300, 100, 100, 300, 300, 100, 100, 300,\n",
       "                    300, 100, 100, 300, 300],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_CLF__penalty': masked_array(data=['l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': True,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'hinge',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 100,\n",
       "   'CLF__penalty': 'l1'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l2'},\n",
       "  {'CLF__early_stopping': False,\n",
       "   'CLF__loss': 'log',\n",
       "   'CLF__max_iter': 300,\n",
       "   'CLF__penalty': 'l1'}],\n",
       " 'rank_test_score': array([12, 10, 11,  9, 13, 13, 15, 16,  2,  7,  3,  8,  5,  1,  4,  6],\n",
       "       dtype=int32),\n",
       " 'split0_test_score': array([0.60857143, 0.59285714, 0.67285714, 0.66428571, 0.72      ,\n",
       "        0.72714286, 0.66571429, 0.70428571, 0.73428571, 0.70142857,\n",
       "        0.71714286, 0.71285714, 0.73428571, 0.72714286, 0.62857143,\n",
       "        0.71428571]),\n",
       " 'split1_test_score': array([0.70714286, 0.73714286, 0.59428571, 0.68285714, 0.71      ,\n",
       "        0.48714286, 0.41714286, 0.53857143, 0.72714286, 0.68285714,\n",
       "        0.74571429, 0.45428571, 0.73285714, 0.74      , 0.74      ,\n",
       "        0.74      ]),\n",
       " 'split2_test_score': array([0.64571429, 0.59714286, 0.70142857, 0.67142857, 0.64      ,\n",
       "        0.68      , 0.64714286, 0.52285714, 0.71285714, 0.68285714,\n",
       "        0.66571429, 0.70571429, 0.66571429, 0.71142857, 0.71      ,\n",
       "        0.68428571]),\n",
       " 'split3_test_score': array([0.66857143, 0.67571429, 0.63571429, 0.72571429, 0.58428571,\n",
       "        0.67571429, 0.68428571, 0.54285714, 0.71571429, 0.54857143,\n",
       "        0.69714286, 0.72714286, 0.72571429, 0.72142857, 0.70428571,\n",
       "        0.73      ]),\n",
       " 'split4_test_score': array([0.70714286, 0.68857143, 0.55428571, 0.68      , 0.41857143,\n",
       "        0.69714286, 0.69857143, 0.67428571, 0.71571429, 0.72428571,\n",
       "        0.72571429, 0.71857143, 0.71      , 0.72857143, 0.73571429,\n",
       "        0.72857143]),\n",
       " 'split5_test_score': array([0.71142857, 0.69      , 0.73428571, 0.68571429, 0.71      ,\n",
       "        0.58714286, 0.63571429, 0.65714286, 0.69857143, 0.73714286,\n",
       "        0.73714286, 0.73857143, 0.65142857, 0.70142857, 0.73714286,\n",
       "        0.69285714]),\n",
       " 'split6_test_score': array([0.50142857, 0.70857143, 0.69714286, 0.72571429, 0.71857143,\n",
       "        0.71      , 0.67142857, 0.69571429, 0.73142857, 0.72714286,\n",
       "        0.69714286, 0.74      , 0.73142857, 0.72285714, 0.73142857,\n",
       "        0.65714286]),\n",
       " 'split7_test_score': array([0.64428571, 0.66428571, 0.68857143, 0.71285714, 0.62428571,\n",
       "        0.71285714, 0.59      , 0.68571429, 0.71142857, 0.72285714,\n",
       "        0.72714286, 0.72      , 0.71142857, 0.72285714, 0.72428571,\n",
       "        0.71428571]),\n",
       " 'split8_test_score': array([0.70857143, 0.70285714, 0.69857143, 0.68714286, 0.69571429,\n",
       "        0.49142857, 0.66714286, 0.49142857, 0.72857143, 0.71285714,\n",
       "        0.73142857, 0.74142857, 0.73857143, 0.73      , 0.67857143,\n",
       "        0.73      ]),\n",
       " 'split9_test_score': array([0.67571429, 0.67571429, 0.72857143, 0.71857143, 0.69285714,\n",
       "        0.74571429, 0.63428571, 0.68      , 0.72571429, 0.75285714,\n",
       "        0.73714286, 0.69857143, 0.72857143, 0.75285714, 0.74571429,\n",
       "        0.73142857]),\n",
       " 'std_fit_time': array([0.05205755, 0.0342076 , 0.03620121, 0.02913184, 0.03956723,\n",
       "        0.04469902, 0.04585984, 0.03530371, 0.05321906, 0.32119413,\n",
       "        0.10546443, 0.19835106, 0.06737777, 0.55668779, 0.16551701,\n",
       "        0.31385191]),\n",
       " 'std_score_time': array([0.00306016, 0.00229236, 0.00225608, 0.00421803, 0.00126853,\n",
       "        0.00202035, 0.00462066, 0.0034264 , 0.00098812, 0.00243849,\n",
       "        0.00325373, 0.00235298, 0.00233731, 0.02118893, 0.00078493,\n",
       "        0.00058814]),\n",
       " 'std_test_score': array([0.06161517, 0.04366874, 0.05545434, 0.02186041, 0.0890769 ,\n",
       "        0.09057864, 0.07698078, 0.0797656 , 0.01054533, 0.05450051,\n",
       "        0.02329973, 0.08165632, 0.02878102, 0.01340804, 0.03429315,\n",
       "        0.02497509])}"
      ]
     },
     "execution_count": 130,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[1].cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlY-SAdYBmty"
   },
   "source": [
    "Accuracy of the best SGD model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PEm-z0w3NiBf",
    "outputId": "170c4845-ac41-481f-edf7-bb14749328e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-micro-score on the testset: 0.9435104236718225\n",
      "F1-macro-score on the testset: 0.24273356401384086\n"
     ]
    }
   ],
   "source": [
    "preds = models[1].predict(df_test['bug'].to_numpy())\n",
    "f1_micro = f1_score(preds, y_test, average='micro')\n",
    "f1_macro = f1_score(preds, y_test, average='macro')\n",
    "print(f'F1-micro-score on the testset: {f1_micro}')\n",
    "print(f'F1-macro-score on the testset: {f1_macro}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kqDIw95Nsr2"
   },
   "source": [
    "Let's check the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "Xeb6jHmeAeVK",
    "outputId": "30e164f5-f8b6-43f5-b02d-c5fac3747d8c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blocker\"</th>\n",
       "      <th>critical\"</th>\n",
       "      <th>major\"</th>\n",
       "      <th>normal\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blocker\"</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>critical\"</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>major\"</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal\"</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           blocker\"  critical\"  major\"  normal\"\n",
       "blocker\"          0          0       0        1\n",
       "critical\"         0          0       0      144\n",
       "major\"            0          0       0       23\n",
       "normal\"           0          0       0     2806"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(le_fitted.classes_)\n",
    "def create_confusion_matrix(num_classes, preds, y_test):\n",
    "    \"\"\"Create confusion matrix 'by hand' since test set does not contain all labels (thanks to Sarah Kiener).\"\"\"\n",
    "    df = pd.DataFrame(np.zeros((num_classes, num_classes), dtype=int))\n",
    "    for i, j in zip(preds, y_test):\n",
    "        df.iloc[i, j] += 1\n",
    "    df.columns = le_fitted.classes_\n",
    "    df.index = le_fitted.classes_\n",
    "    return df\n",
    "df = create_confusion_matrix(num_classes, preds, y_test)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dataseminar.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
